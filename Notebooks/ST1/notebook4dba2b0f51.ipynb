{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "collapsed_sections": [
        "TqgRNRHwiz4Y",
        "K1XdGsNZi5Mp",
        "465N4SEyiuAO",
        "-Q_9l5oMWxA0",
        "d_8B_Wo0Y4b2",
        "uFjG06XBZWCI",
        "of2EPdkmIzhP",
        "PkRgo9xV0kVE"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b2239a2c0a748e79402467f7a150bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5a4caf22b4c44c89657e927be935db0",
              "IPY_MODEL_11b449ff61b042ac8459dae786abd71c",
              "IPY_MODEL_8494f14d69f04423bacbb85c752c2000"
            ],
            "layout": "IPY_MODEL_8c851b2245ec4a36a831f15e01495ced"
          }
        },
        "f5a4caf22b4c44c89657e927be935db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f32fada4a8040cdaac7a45627391c91",
            "placeholder": "​",
            "style": "IPY_MODEL_8728206835f84335bd48e562bdcaeaee",
            "value": "Map: 100%"
          }
        },
        "11b449ff61b042ac8459dae786abd71c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67e2ede5e2d742b28549ff1a7810f382",
            "max": 8272,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d1b4afd11584ef9a5c4629794231101",
            "value": 8272
          }
        },
        "8494f14d69f04423bacbb85c752c2000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36a6ba32b73f423d9c8d95c8f670ce1e",
            "placeholder": "​",
            "style": "IPY_MODEL_083e07d00ee34b899441a3b301342f08",
            "value": " 8272/8272 [01:24&lt;00:00, 148.45 examples/s]"
          }
        },
        "8c851b2245ec4a36a831f15e01495ced": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f32fada4a8040cdaac7a45627391c91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8728206835f84335bd48e562bdcaeaee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67e2ede5e2d742b28549ff1a7810f382": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d1b4afd11584ef9a5c4629794231101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36a6ba32b73f423d9c8d95c8f670ce1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "083e07d00ee34b899441a3b301342f08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de5e1dbe86dc4722bb3164e15ed00b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55f173c83fcb4bbe838d2bf26527ed9a",
              "IPY_MODEL_49202a3183c14b9ca7467ce866055db0",
              "IPY_MODEL_8fc9a724f01246b09f18a606beba8703"
            ],
            "layout": "IPY_MODEL_0d7c3c43a79a4244a7d21181430e272e"
          }
        },
        "55f173c83fcb4bbe838d2bf26527ed9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_630746e51eaa4667acc616ae066465b9",
            "placeholder": "​",
            "style": "IPY_MODEL_c44e14c1b2de428fbf2d517bd1edebc7",
            "value": "Map: 100%"
          }
        },
        "49202a3183c14b9ca7467ce866055db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_833a17c608104c2b823eb6791819e242",
            "max": 509,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad65ed77bc154f6bb7746a9701659665",
            "value": 509
          }
        },
        "8fc9a724f01246b09f18a606beba8703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfcb3fb3c0bb4fc7831f2143fe4b0728",
            "placeholder": "​",
            "style": "IPY_MODEL_96f8c95c8e3848c9b9cad8b2b9ebad8a",
            "value": " 509/509 [00:08&lt;00:00, 59.30 examples/s]"
          }
        },
        "0d7c3c43a79a4244a7d21181430e272e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "630746e51eaa4667acc616ae066465b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c44e14c1b2de428fbf2d517bd1edebc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "833a17c608104c2b823eb6791819e242": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad65ed77bc154f6bb7746a9701659665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfcb3fb3c0bb4fc7831f2143fe4b0728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96f8c95c8e3848c9b9cad8b2b9ebad8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52cc9c0d5ea044a08b98b4478532b482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e81776dcbc8f4c8b9eff76ddb5578c72",
              "IPY_MODEL_5f843d7b98f54d13ab9fa61fb03fd5b2",
              "IPY_MODEL_d343b5e26bc5453c80430ba3520794e1"
            ],
            "layout": "IPY_MODEL_3f9de437528741b5bcea6257d48d629f"
          }
        },
        "e81776dcbc8f4c8b9eff76ddb5578c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1e22564cb39434cabd557c547db49fb",
            "placeholder": "​",
            "style": "IPY_MODEL_b400753b3ca74e58be712eceaff4e33c",
            "value": "config.json: 100%"
          }
        },
        "5f843d7b98f54d13ab9fa61fb03fd5b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42e8f9b5629e4dbcabeffb1211f367b2",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_016e389c87574837990ba6007d57e28c",
            "value": 481
          }
        },
        "d343b5e26bc5453c80430ba3520794e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac29d3acc38e48acbc44a6644a018e32",
            "placeholder": "​",
            "style": "IPY_MODEL_7281d98b82fb47d892b3810aba0c8f17",
            "value": " 481/481 [00:00&lt;00:00, 24.1kB/s]"
          }
        },
        "3f9de437528741b5bcea6257d48d629f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1e22564cb39434cabd557c547db49fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b400753b3ca74e58be712eceaff4e33c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42e8f9b5629e4dbcabeffb1211f367b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "016e389c87574837990ba6007d57e28c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac29d3acc38e48acbc44a6644a018e32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7281d98b82fb47d892b3810aba0c8f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b709f12bab5448a862d5701c85e6d1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c5e3855b87344aeaed42558558ae34f",
              "IPY_MODEL_c9394f129d5d495cb6f7e990aa37dada",
              "IPY_MODEL_0b0e245722804685b066d442801d8feb"
            ],
            "layout": "IPY_MODEL_2bfa6dfe29634e598949116a54666a5c"
          }
        },
        "2c5e3855b87344aeaed42558558ae34f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a73ba9f383c34eddae1226cc2bcc4106",
            "placeholder": "​",
            "style": "IPY_MODEL_9cca96b859f341bdbeac80b728eed320",
            "value": "model.safetensors: 100%"
          }
        },
        "c9394f129d5d495cb6f7e990aa37dada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea35d79ead4b4899b7ef1884cdc46544",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2c55ac403e347e5a63e7f8ad2d1d78a",
            "value": 498818054
          }
        },
        "0b0e245722804685b066d442801d8feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60056fb76eb94e38b311e42bd82dd19c",
            "placeholder": "​",
            "style": "IPY_MODEL_8df8a25a55d04378800436c7821e7801",
            "value": " 499M/499M [00:02&lt;00:00, 250MB/s]"
          }
        },
        "2bfa6dfe29634e598949116a54666a5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a73ba9f383c34eddae1226cc2bcc4106": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cca96b859f341bdbeac80b728eed320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea35d79ead4b4899b7ef1884cdc46544": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2c55ac403e347e5a63e7f8ad2d1d78a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60056fb76eb94e38b311e42bd82dd19c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8df8a25a55d04378800436c7821e7801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f56d659f41bf4583ba5fce28a61d51e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d77334fc5eb469d98e7a4f397c0d568",
              "IPY_MODEL_be5a8b40df3948c98bc1690780804266",
              "IPY_MODEL_8f9b2080dbc34bd6be6f36c44d9b1afc"
            ],
            "layout": "IPY_MODEL_c58f6ef7f9824805a4c774fa87532a59"
          }
        },
        "5d77334fc5eb469d98e7a4f397c0d568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9f63fa3ee4d441ca5b7aaa87aa60730",
            "placeholder": "​",
            "style": "IPY_MODEL_51360b7443d0487aa852d2bc0ce1e044",
            "value": "  1%"
          }
        },
        "be5a8b40df3948c98bc1690780804266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc3363e1c56e4f518df848f4ed59e490",
            "max": 5170,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_747bcacff49841c9bd87303602192f1c",
            "value": 39
          }
        },
        "8f9b2080dbc34bd6be6f36c44d9b1afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_455b116f5dd044c3874dc0edcc990067",
            "placeholder": "​",
            "style": "IPY_MODEL_c50ca5f30ae04abf86eb4bfbad9555d3",
            "value": " 39/5170 [00:30&lt;1:03:40,  1.34it/s]"
          }
        },
        "c58f6ef7f9824805a4c774fa87532a59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9f63fa3ee4d441ca5b7aaa87aa60730": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51360b7443d0487aa852d2bc0ce1e044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc3363e1c56e4f518df848f4ed59e490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "747bcacff49841c9bd87303602192f1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "455b116f5dd044c3874dc0edcc990067": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c50ca5f30ae04abf86eb4bfbad9555d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10467857,
          "sourceType": "datasetVersion",
          "datasetId": 6481190
        },
        {
          "sourceId": 10499916,
          "sourceType": "datasetVersion",
          "datasetId": 6501005
        }
      ],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/food-hazard-detection-semeval-2025/food-hazard-detection-semeval-2025.github.io/blob/main/code/The_Food_Hazard_Detection_Challenge_SemEval_2025_The_BERT_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install torch transformers datasets pandas scikit-learn pickle openai google-generativeai anthropic numpy"
      ],
      "metadata": {
        "id": "tkU4F88ORjFv",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T08:07:18.358912Z",
          "iopub.execute_input": "2025-01-16T08:07:18.359224Z",
          "iopub.status.idle": "2025-01-16T08:07:20.253987Z",
          "shell.execute_reply.started": "2025-01-16T08:07:18.359201Z",
          "shell.execute_reply": "2025-01-16T08:07:20.252824Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install nlpaug\n",
        "!pip install sacremoses"
      ],
      "metadata": {
        "id": "IBxjil7V0rj2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T08:08:47.726876Z",
          "iopub.execute_input": "2025-01-16T08:08:47.727260Z",
          "iopub.status.idle": "2025-01-16T08:08:54.621788Z",
          "shell.execute_reply.started": "2025-01-16T08:08:47.727232Z",
          "shell.execute_reply": "2025-01-16T08:08:54.620724Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install --upgrade datasets"
      ],
      "metadata": {
        "id": "X8-ZF3-M4xaA",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T08:07:28.934852Z",
          "iopub.execute_input": "2025-01-16T08:07:28.935152Z",
          "iopub.status.idle": "2025-01-16T08:07:32.126616Z",
          "shell.execute_reply.started": "2025-01-16T08:07:28.935117Z",
          "shell.execute_reply": "2025-01-16T08:07:32.125537Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/food-hazard-detection-semeval-2025/food-hazard-detection-semeval-2025.github.io.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dlvS4QLGAsw",
        "outputId": "e7b70237-ca94-4c92-93ba-bb1cc2a1204d",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T08:07:32.128000Z",
          "iopub.execute_input": "2025-01-16T08:07:32.128322Z",
          "iopub.status.idle": "2025-01-16T08:07:33.337193Z",
          "shell.execute_reply.started": "2025-01-16T08:07:32.128300Z",
          "shell.execute_reply": "2025-01-16T08:07:33.336361Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Cloning into 'food-hazard-detection-semeval-2025.github.io'...\nremote: Enumerating objects: 130, done.\u001b[K\nremote: Counting objects: 100% (130/130), done.\u001b[K\nremote: Compressing objects: 100% (107/107), done.\u001b[K\nremote: Total 130 (delta 60), reused 60 (delta 18), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (130/130), 4.00 MiB | 20.50 MiB/s, done.\nResolving deltas: 100% (60/60), done.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "import pandas as pd\n",
        "data = pd.read_csv('food-hazard-detection-semeval-2025.github.io/data/incidents_train.csv', index_col=0)\n",
        "data.sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "cM9ZnMwdRb32",
        "outputId": "5b0ddfbc-5800-408e-e63f-68f252ffecc7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T08:07:33.338198Z",
          "iopub.execute_input": "2025-01-16T08:07:33.338508Z",
          "iopub.status.idle": "2025-01-16T08:07:38.850161Z",
          "shell.execute_reply.started": "2025-01-16T08:07:33.338485Z",
          "shell.execute_reply": "2025-01-16T08:07:38.849301Z"
        }
      },
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "      year  month  day country  \\\n1228  2015      3   19      ca   \n\n                                                 title  \\\n1228  Organic garlic powder recalled due to Salmonella   \n\n                                                   text hazard-category  \\\n1228  Notice This archive of previously issued food ...      biological   \n\n           product-category      hazard        product  \n1228  fruits and vegetables  salmonella  garlic powder  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>country</th>\n      <th>title</th>\n      <th>text</th>\n      <th>hazard-category</th>\n      <th>product-category</th>\n      <th>hazard</th>\n      <th>product</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1228</th>\n      <td>2015</td>\n      <td>3</td>\n      <td>19</td>\n      <td>ca</td>\n      <td>Organic garlic powder recalled due to Salmonella</td>\n      <td>Notice This archive of previously issued food ...</td>\n      <td>biological</td>\n      <td>fruits and vegetables</td>\n      <td>salmonella</td>\n      <td>garlic powder</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import BertTokenizer, XLMRobertaTokenizer, XLMRobertaForSequenceClassification, XLMRobertaModel, BertForSequenceClassification, AdamW, get_scheduler, DataCollatorWithPadding, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import classification_report\n",
        "import pickle\n",
        "from google.colab import userdata, drive\n",
        "from typing_extensions import TypedDict\n",
        "import json\n",
        "import re\n",
        "import time\n",
        "import requests\n",
        "import google.generativeai as genai\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "605zlIAbRvf2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T08:08:59.510486Z",
          "iopub.execute_input": "2025-01-16T08:08:59.510796Z",
          "iopub.status.idle": "2025-01-16T08:09:20.346257Z",
          "shell.execute_reply.started": "2025-01-16T08:08:59.510771Z",
          "shell.execute_reply": "2025-01-16T08:09:20.345262Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "import random\n",
        "import nltk\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T08:09:20.347499Z",
          "iopub.execute_input": "2025-01-16T08:09:20.348085Z",
          "iopub.status.idle": "2025-01-16T08:09:20.407282Z",
          "shell.execute_reply.started": "2025-01-16T08:09:20.348059Z",
          "shell.execute_reply": "2025-01-16T08:09:20.406529Z"
        },
        "id": "CS5XuGL15KNk",
        "outputId": "7ccd6644-7258-4b7e-8cc5-7a7cca78bfd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n",
          "output_type": "stream"
        },
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "nltk_data_path = '/usr/share/nltk_data/corpora'\n",
        "\n",
        "# Unzip wordnet.zip\n",
        "with zipfile.ZipFile(os.path.join(nltk_data_path, 'wordnet.zip'), 'r') as zip_ref:\n",
        "    zip_ref.extractall(nltk_data_path)\n",
        "\n",
        "# Unzip omw-1.4.zip\n",
        "with zipfile.ZipFile(os.path.join(nltk_data_path, 'omw-1.4.zip'), 'r') as zip_ref:\n",
        "    zip_ref.extractall(nltk_data_path)\n",
        "\n",
        "print(\"Unzipping complete!\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T08:09:20.408506Z",
          "iopub.execute_input": "2025-01-16T08:09:20.408699Z",
          "iopub.status.idle": "2025-01-16T08:09:21.287913Z",
          "shell.execute_reply.started": "2025-01-16T08:09:20.408682Z",
          "shell.execute_reply": "2025-01-16T08:09:21.286795Z"
        },
        "id": "ajuh_JO-5KNk",
        "outputId": "ce2e8b8a-1a73-4b8f-beb3-928896540f24"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Unzipping complete!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "\n",
        "try:\n",
        "    wordnet.synsets('example')\n",
        "    print(\"WordNet is accessible.\")\n",
        "except LookupError as e:\n",
        "    print(\"Error accessing WordNet:\", e)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T08:09:21.289037Z",
          "iopub.execute_input": "2025-01-16T08:09:21.289416Z",
          "iopub.status.idle": "2025-01-16T08:09:21.294056Z",
          "shell.execute_reply.started": "2025-01-16T08:09:21.289381Z",
          "shell.execute_reply": "2025-01-16T08:09:21.293408Z"
        },
        "id": "3Mtj1iDw5KNk",
        "outputId": "bc8a5371-a412-4785-89be-d0e7fca5e262"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "WordNet is accessible.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Categories to augment\n",
        "categories_to_augment = [\"packaging defect\", \"other hazard\", \"fraud\", \"food additives and flavourings\"]\n",
        "augmentation_samples_per_technique = 200  # 200 samples per technique per category\n",
        "\n",
        "# Initialize augmenters\n",
        "synonym_aug = naw.SynonymAug(aug_min=10, aug_max=20)  # Synonym replacement\n",
        "contextual_aug = naw.ContextualWordEmbsAug(model_path='distilbert-base-uncased', aug_p=0.2, device='cuda')  # Contextual embeddings\n",
        "\n",
        "# DataFrame to store augmented data\n",
        "augmented_data = []\n",
        "\n",
        "# Loop through each category to augment\n",
        "for category in categories_to_augment:\n",
        "    # Filter data for the current category\n",
        "    category_data = data[data['hazard-category'] == category]\n",
        "\n",
        "    if len(category_data) == 0:\n",
        "        print(f\"No data available for category: {category}\")\n",
        "        continue\n",
        "\n",
        "    for augmenter, name in zip([synonym_aug, contextual_aug], [\"synonym\", \"contextual\"]):\n",
        "        print(f\"Augmenting {category} with {name} augmentation...\")\n",
        "\n",
        "        # Reset counter for each technique\n",
        "        augmented_rows = []\n",
        "        while len(augmented_rows) < augmentation_samples_per_technique:\n",
        "            # Shuffle the data to ensure randomness\n",
        "            category_data = shuffle(category_data)\n",
        "            # Cycle through the available rows if fewer rows exist\n",
        "            for _, sample in category_data.iterrows():\n",
        "                if len(augmented_rows) >= augmentation_samples_per_technique:\n",
        "                    break\n",
        "\n",
        "                # Apply augmentation to title and text\n",
        "                augmented_title = augmenter.augment(sample['title'])\n",
        "                augmented_text = augmenter.augment(sample['text'])\n",
        "\n",
        "                # Create a new row with augmented data\n",
        "                new_row = sample.copy()\n",
        "                new_row['title'] = augmented_title\n",
        "                new_row['text'] = augmented_text\n",
        "                augmented_rows.append(new_row)\n",
        "\n",
        "        # Add the augmented rows to the global list\n",
        "        augmented_data.extend(augmented_rows)\n",
        "\n",
        "# Convert augmented data to DataFrame\n",
        "augmented_data_df = pd.DataFrame(augmented_data)\n",
        "\n",
        "# Save augmented data to a file\n",
        "augmented_data_df.to_csv('augmented_data_step1.csv', index=False)\n",
        "\n",
        "print(\"Augmentation for multiple categories complete. Data saved to 'augmented_data_step1.csv'.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "v9NftY0k5KNk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import nlpaug.augmenter.word as naw\n",
        "from sklearn.utils import shuffle\n",
        "import pandas as pd\n",
        "\n",
        "# Focus on the \"fraud\" category only\n",
        "category_to_augment = \"fraud\"\n",
        "augmentation_samples_per_technique = 600  # Samples per technique\n",
        "\n",
        "# Initialize augmenters\n",
        "synonym_aug = naw.SynonymAug(aug_min=20, aug_max=50)  # Synonym replacement\n",
        "contextual_aug = naw.ContextualWordEmbsAug(model_path='distilbert-base-uncased', aug_p=0.8, device='cuda')  # Contextual embeddings\n",
        "random_aug = naw.RandomWordAug(action=\"substitute\", aug_p=0.20)  # Random word substitution (fixing the issue)\n",
        "\n",
        "# DataFrame to store augmented data\n",
        "augmented_data = []\n",
        "\n",
        "# Filter data for the \"fraud\" category\n",
        "fraud_data = data[data['hazard-category'] == category_to_augment]\n",
        "\n",
        "if len(fraud_data) == 0:\n",
        "    print(f\"No data available for category: {category_to_augment}\")\n",
        "else:\n",
        "    print(f\"Augmenting the '{category_to_augment}' category...\")\n",
        "\n",
        "    # Loop through each augmenter\n",
        "    for augmenter, name in zip([synonym_aug, contextual_aug, random_aug], [\"synonym\", \"contextual\", \"random\"]):\n",
        "        print(f\"Using {name} augmentation...\")\n",
        "\n",
        "        # Reset counter for each technique\n",
        "        augmented_rows = []\n",
        "        while len(augmented_rows) < augmentation_samples_per_technique:\n",
        "            # Shuffle the data to ensure randomness\n",
        "            fraud_data = shuffle(fraud_data)\n",
        "\n",
        "            # Cycle through the available rows if fewer rows exist\n",
        "            for _, sample in fraud_data.iterrows():\n",
        "                if len(augmented_rows) >= augmentation_samples_per_technique:\n",
        "                    break\n",
        "\n",
        "                # Apply augmentation to title and text\n",
        "                augmented_title = augmenter.augment(sample['title'])\n",
        "                augmented_text = augmenter.augment(sample['text'])\n",
        "\n",
        "                # Create a new row with augmented data\n",
        "                new_row = sample.copy()\n",
        "                new_row['title'] = augmented_title\n",
        "                new_row['text'] = augmented_text\n",
        "                augmented_rows.append(new_row)\n",
        "\n",
        "        # Add the augmented rows to the global list\n",
        "        augmented_data.extend(augmented_rows)\n",
        "\n",
        "# Convert augmented data to DataFrame\n",
        "augmented_fraud_df = pd.DataFrame(augmented_data)\n",
        "\n",
        "# Load previous augmented data from step 1\n",
        "previous_augmented_data_df = pd.read_csv('augmented_data_step1.csv')\n",
        "\n",
        "# Concatenate the new fraud-augmented data with the previous data\n",
        "augmented_data_df = pd.concat([previous_augmented_data_df, augmented_fraud_df], ignore_index=True)\n",
        "\n",
        "# Save the final augmented data\n",
        "augmented_data_df.to_csv('final_augmented_data.csv', index=False)\n",
        "\n",
        "print(\"Augmentation for 'fraud' category complete. Final DataFrame is named 'augmented_data_df' and saved to 'final_augmented_data.csv'.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "3VwhF1JN5KNl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Categories to augment\n",
        "categories_to_augment = [\"seafood\", \"soups, broths, sauces and condiments\", \"nuts, nut products and seeds\", \"ices and desserts\", \"cocoa and cocoa preparations, coffee and tea\", \"confectionery\", \"non-alcoholic beverages\", \"dietetic foods, food supplements, fortified foods\", \"herbs and spices\", \"alcoholic beverages\", \"other food product / mixed\", \"pet feed\", \"fats and oils\", \"food additives and flavourings\", \"honey and royal jelly\", \"food contact materials\", \"feed materials\", \"sugars and syrups\"]\n",
        "augmentation_samples_per_technique = 200  # 200 samples per technique per category\n",
        "\n",
        "# Initialize augmenters\n",
        "synonym_aug = naw.SynonymAug(aug_min=10, aug_max=20)  # Synonym replacement\n",
        "contextual_aug = naw.ContextualWordEmbsAug(model_path='distilbert-base-uncased', aug_p=0.2, device='cuda')  # Contextual embeddings\n",
        "random_aug = naw.RandomWordAug(action=\"substitute\", aug_p=0.1)  # Random word substitution (fixing the issue)\n",
        "\n",
        "# DataFrame to store augmented data\n",
        "augmented_data = []\n",
        "\n",
        "# Loop through each category to augment\n",
        "for category in categories_to_augment:\n",
        "    # Filter data for the current category\n",
        "    category_data = data[data['product-category'] == category]\n",
        "\n",
        "    if len(category_data) == 0:\n",
        "        print(f\"No data available for category: {category}\")\n",
        "        continue\n",
        "\n",
        "    for augmenter, name in zip([synonym_aug, contextual_aug, random_aug], [\"synonym\", \"contextual\", \"random_aug\"]):\n",
        "        print(f\"Augmenting {category} with {name} augmentation...\")\n",
        "\n",
        "        # Reset counter for each technique\n",
        "        augmented_rows = []\n",
        "        while len(augmented_rows) < augmentation_samples_per_technique:\n",
        "            # Shuffle the data to ensure randomness\n",
        "            category_data = shuffle(category_data)\n",
        "            # Cycle through the available rows if fewer rows exist\n",
        "            for _, sample in category_data.iterrows():\n",
        "                if len(augmented_rows) >= augmentation_samples_per_technique:\n",
        "                    break\n",
        "\n",
        "                # Apply augmentation to title and text\n",
        "                augmented_title = augmenter.augment(sample['title'])\n",
        "                augmented_text = augmenter.augment(sample['text'])\n",
        "\n",
        "                # Create a new row with augmented data\n",
        "                new_row = sample.copy()\n",
        "                new_row['title'] = augmented_title\n",
        "                new_row['text'] = augmented_text\n",
        "                augmented_rows.append(new_row)\n",
        "\n",
        "        # Add the augmented rows to the global list\n",
        "        augmented_data.extend(augmented_rows)\n",
        "\n",
        "# Convert augmented data to DataFrame\n",
        "augmented_data_df = pd.DataFrame(augmented_data)\n",
        "\n",
        "# Save augmented data to a file\n",
        "augmented_data_df.to_csv('augmented_data_step1.csv', index=False)\n",
        "\n",
        "print(\"Augmentation for multiple categories complete. Data saved to 'augmented_data_step1.csv'.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T08:09:27.505997Z",
          "iopub.execute_input": "2025-01-16T08:09:27.506359Z",
          "iopub.status.idle": "2025-01-16T08:26:14.055400Z",
          "shell.execute_reply.started": "2025-01-16T08:09:27.506328Z",
          "shell.execute_reply": "2025-01-16T08:26:14.054467Z"
        },
        "id": "KonYnMGt5KNl",
        "outputId": "000e87b4-92cb-4e2c-e57c-ec6e81eb3abc",
        "colab": {
          "referenced_widgets": [
            "5fb6efa7098e41f0aef66d0d8148b31b",
            "474df9fb32424e78acfff96083e4bf68",
            "884eb0ed8b1d447e86496a81e3e3fd19",
            "2c7bd135fe99488499727868b9152cb7",
            "092982ebf0e5404a8ed67840a811daf1"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fb6efa7098e41f0aef66d0d8148b31b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "474df9fb32424e78acfff96083e4bf68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "884eb0ed8b1d447e86496a81e3e3fd19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c7bd135fe99488499727868b9152cb7"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "092982ebf0e5404a8ed67840a811daf1"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Augmenting seafood with synonym augmentation...\nAugmenting seafood with contextual augmentation...\nAugmenting seafood with random_aug augmentation...\nAugmenting soups, broths, sauces and condiments with synonym augmentation...\nAugmenting soups, broths, sauces and condiments with contextual augmentation...\nAugmenting soups, broths, sauces and condiments with random_aug augmentation...\nAugmenting nuts, nut products and seeds with synonym augmentation...\nAugmenting nuts, nut products and seeds with contextual augmentation...\nAugmenting nuts, nut products and seeds with random_aug augmentation...\nAugmenting ices and desserts with synonym augmentation...\nAugmenting ices and desserts with contextual augmentation...\nAugmenting ices and desserts with random_aug augmentation...\nAugmenting cocoa and cocoa preparations, coffee and tea with synonym augmentation...\nAugmenting cocoa and cocoa preparations, coffee and tea with contextual augmentation...\nAugmenting cocoa and cocoa preparations, coffee and tea with random_aug augmentation...\nAugmenting confectionery with synonym augmentation...\nAugmenting confectionery with contextual augmentation...\nAugmenting confectionery with random_aug augmentation...\nAugmenting non-alcoholic beverages with synonym augmentation...\nAugmenting non-alcoholic beverages with contextual augmentation...\nAugmenting dietetic foods, food supplements, fortified foods with synonym augmentation...\nAugmenting dietetic foods, food supplements, fortified foods with contextual augmentation...\nAugmenting dietetic foods, food supplements, fortified foods with random_aug augmentation...\nAugmenting herbs and spices with synonym augmentation...\nAugmenting herbs and spices with contextual augmentation...\nAugmenting herbs and spices with random_aug augmentation...\nAugmenting alcoholic beverages with synonym augmentation...\nAugmenting alcoholic beverages with contextual augmentation...\nAugmenting alcoholic beverages with random_aug augmentation...\nAugmenting other food product / mixed with synonym augmentation...\nAugmenting other food product / mixed with contextual augmentation...\nAugmenting other food product / mixed with random_aug augmentation...\nAugmenting pet feed with synonym augmentation...\nAugmenting pet feed with contextual augmentation...\nAugmenting pet feed with random_aug augmentation...\nAugmenting fats and oils with synonym augmentation...\nAugmenting fats and oils with contextual augmentation...\nAugmenting fats and oils with random_aug augmentation...\nAugmenting food additives and flavourings with synonym augmentation...\nAugmenting food additives and flavourings with contextual augmentation...\nAugmenting food additives and flavourings with random_aug augmentation...\nAugmenting honey and royal jelly with synonym augmentation...\nAugmenting honey and royal jelly with contextual augmentation...\nAugmenting honey and royal jelly with random_aug augmentation...\nAugmenting food contact materials with synonym augmentation...\nAugmenting food contact materials with contextual augmentation...\nAugmenting food contact materials with random_aug augmentation...\nAugmenting feed materials with synonym augmentation...\nAugmenting feed materials with contextual augmentation...\nAugmenting feed materials with random_aug augmentation...\nAugmenting sugars and syrups with synonym augmentation...\nAugmenting sugars and syrups with contextual augmentation...\nAugmenting sugars and syrups with random_aug augmentation...\nAugmentation for multiple categories complete. Data saved to 'augmented_data_step1.csv'.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "synthesized_df = pd.DataFrame()\n",
        "generated_data = pd.read_csv('/kaggle/input/gemini/Gemini/gemini_augmented.csv', index_col=0)\n",
        "synthesized_df = pd.concat([synthesized_df, generated_data])\n",
        "generated_data = pd.read_csv('/kaggle/input/gemini/Gemini/gemini_augmented_2.csv', index_col=0)\n",
        "synthesized_df = pd.concat([synthesized_df, generated_data])\n",
        "generated_data = pd.read_csv('/kaggle/input/gemini/Gemini/gemini_augmented_3.csv', index_col=0)\n",
        "synthesized_df = pd.concat([synthesized_df, generated_data])\n",
        "generated_data = pd.read_csv('/kaggle/input/gemini/Gemini/gemini_augmented_4.csv', index_col=0)\n",
        "synthesized_df = pd.concat([synthesized_df, generated_data])\n",
        "generated_data = pd.read_csv('/kaggle/input/gemini/Gemini/gemini_augmented_5.csv', index_col=0)\n",
        "synthesized_df = pd.concat([synthesized_df, generated_data])\n",
        "generated_data = pd.read_csv('/kaggle/input/gemini/Gemini/gemini_augmented_6.csv', index_col=0)\n",
        "synthesized_df = pd.concat([synthesized_df, generated_data])\n",
        "generated_data = pd.read_csv('/kaggle/input/gemini/Gemini/gemini_augmented_product.csv', index_col=0)\n",
        "synthesized_df = pd.concat([synthesized_df, generated_data])\n",
        "generated_data = pd.read_csv('/kaggle/input/gemini/Gemini/gemini_augmented_product_2.csv', index_col=0)\n",
        "synthesized_df = pd.concat([synthesized_df, generated_data])\n",
        "generated_data = pd.read_csv('/kaggle/input/gemini/Gemini/gemini_augmented_product_3.csv', index_col=0)\n",
        "synthesized_df = pd.concat([synthesized_df, generated_data])\n",
        "generated_data = pd.read_csv('/kaggle/input/gemini/Gemini/gemini_augmented_product_4.csv', index_col=0)\n",
        "synthesized_df = pd.concat([synthesized_df, generated_data])\n",
        "generated_data = pd.read_csv('/kaggle/input/gemini/Gemini/gemini_augmented_product_5.csv', index_col=0)\n",
        "synthesized_df = pd.concat([synthesized_df, generated_data])"
      ],
      "metadata": {
        "id": "6Ggbz7R5WYZl",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T08:37:04.697849Z",
          "iopub.execute_input": "2025-01-16T08:37:04.698232Z",
          "iopub.status.idle": "2025-01-16T08:37:04.899521Z",
          "shell.execute_reply.started": "2025-01-16T08:37:04.698203Z",
          "shell.execute_reply": "2025-01-16T08:37:04.898733Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rest Code"
      ],
      "metadata": {
        "id": "465N4SEyiuAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['title_text'] = data['title'] + ' ' + data['text']\n",
        "synthesized_df['title_text'] = synthesized_df['title'] + ' ' + synthesized_df['text']\n",
        "augmented_data_df['title'] = augmented_data_df['title'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
        "augmented_data_df['text'] = augmented_data_df['text'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
        "augmented_data_df['title'] = augmented_data_df['title'].astype(str)\n",
        "augmented_data_df['text'] = augmented_data_df['text'].astype(str)\n",
        "augmented_data_df['title_text'] = augmented_data_df['title'] + ' ' + augmented_data_df['text']\n",
        "\n",
        "# data['title_text'] = 'Hazard Category: ' + data['hazard-category'] + ' ' + data['title'] + ' ' + data['text']\n",
        "# synthesized_df['title_text'] = 'Hazard Category: ' + synthesized_df['hazard-category'] + ' ' + synthesized_df['title'] + ' ' + synthesized_df['text']"
      ],
      "metadata": {
        "id": "TCnTra3lRDSf",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T08:37:10.181806Z",
          "iopub.execute_input": "2025-01-16T08:37:10.182121Z",
          "iopub.status.idle": "2025-01-16T08:37:10.255751Z",
          "shell.execute_reply.started": "2025-01-16T08:37:10.182097Z",
          "shell.execute_reply": "2025-01-16T08:37:10.255088Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "tokenizer.save_pretrained('./tokenizer')\n",
        "# tokenizer.save_pretrained('/content/drive/My Drive/FoodHazardData/tokenizer')\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['title_text'], padding=True, truncation=True)"
      ],
      "metadata": {
        "id": "GDJkctu9XKvi",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T08:37:22.241698Z",
          "iopub.execute_input": "2025-01-16T08:37:22.242033Z",
          "iopub.status.idle": "2025-01-16T08:37:22.331535Z",
          "shell.execute_reply.started": "2025-01-16T08:37:22.242006Z",
          "shell.execute_reply": "2025-01-16T08:37:22.330880Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label: `Hazard Category`"
      ],
      "metadata": {
        "id": "UMbumTEsW5No"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Choose your target"
      ],
      "metadata": {
        "id": "lK9Xj8TcYiwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = 'hazard-category' # change this to: 'product-category', 'hazard', 'product' to alter the ground truth\n",
        "label_encoder = LabelEncoder()\n",
        "data['label'] = label_encoder.fit_transform(data[label])\n",
        "synthesized_df['label'] = label_encoder.transform(synthesized_df[label])\n",
        "augmented_data_df['label'] = label_encoder.transform(augmented_data_df[label])\n",
        "\n",
        "with open(f'{label}_label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoder, f)"
      ],
      "metadata": {
        "id": "svEVrEmiduCH",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T08:37:27.244412Z",
          "iopub.execute_input": "2025-01-16T08:37:27.244699Z",
          "iopub.status.idle": "2025-01-16T08:37:27.254465Z",
          "shell.execute_reply.started": "2025-01-16T08:37:27.244678Z",
          "shell.execute_reply": "2025-01-16T08:37:27.253647Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df, test_df = train_test_split(data, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "cf2iCxlIeetq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T06:50:10.761719Z",
          "iopub.execute_input": "2025-01-16T06:50:10.761992Z",
          "iopub.status.idle": "2025-01-16T06:50:10.779092Z",
          "shell.execute_reply.started": "2025-01-16T06:50:10.761968Z",
          "shell.execute_reply": "2025-01-16T06:50:10.778288Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "import random\n",
        "import nltk\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# ----------------------------\n",
        "# 1. Synonym Replacement Functions\n",
        "# ----------------------------\n",
        "def get_synonyms(word):\n",
        "    \"\"\"Retrieve synonyms for a given word using WordNet.\"\"\"\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonym = lemma.name().replace('_', ' ').lower()\n",
        "            if synonym != word.lower():\n",
        "                synonyms.add(synonym)\n",
        "    return list(synonyms)\n",
        "\n",
        "def synonym_replacement(sentence, n=1):\n",
        "    \"\"\"\n",
        "    Replace up to n words in the sentence with their synonyms.\n",
        "\n",
        "    Args:\n",
        "        sentence (str): The original sentence.\n",
        "        n (int): Number of words to replace.\n",
        "\n",
        "    Returns:\n",
        "        str: The augmented sentence.\n",
        "    \"\"\"\n",
        "    words = sentence.split()\n",
        "    new_words = words.copy()\n",
        "    eligible_words = [word for word in words if word.isalpha()]\n",
        "    random.shuffle(eligible_words)\n",
        "    num_replaced = 0\n",
        "\n",
        "    for random_word in eligible_words:\n",
        "        synonyms = get_synonyms(random_word)\n",
        "        if synonyms:\n",
        "            synonym = random.choice(synonyms)\n",
        "            new_words = [synonym if word == random_word else word for word in new_words]\n",
        "            num_replaced += 1\n",
        "        if num_replaced >= n:\n",
        "            break\n",
        "\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Data Splitting\n",
        "# ----------------------------\n",
        "# Split the data into training and testing sets\n",
        "train_df, test_df = train_test_split(data, test_size=0.1, random_state=42)\n",
        "train_df = pd.concat([train_df, synthesized_df], ignore_index=True)\n",
        "train_df = pd.concat([train_df, augmented_data_df], ignore_index=True)\n",
        "\n",
        "print(f\"Final augmented training set size: {len(train_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHlFIBJ50LPN",
        "outputId": "b1163598-0a9b-4293-d276-c4ef555e4715",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T08:37:36.349081Z",
          "iopub.execute_input": "2025-01-16T08:37:36.349398Z",
          "iopub.status.idle": "2025-01-16T08:37:36.369804Z",
          "shell.execute_reply.started": "2025-01-16T08:37:36.349375Z",
          "shell.execute_reply": "2025-01-16T08:37:36.369045Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\nFinal augmented training set size: 19072\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Data preprocessing"
      ],
      "metadata": {
        "id": "c3XAnaaCYhIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "# train_df, test_df = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert DataFrame to Hugging Face Dataset\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Apply the tokenizer to the dataset\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Create DataCollator to handle padding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True, max_length=16)\n",
        "\n",
        "# Convert dataset to PyTorch format\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# Create DataLoader objects\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=8, collate_fn=data_collator)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=8, collate_fn=data_collator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "0b2239a2c0a748e79402467f7a150bb8",
            "f5a4caf22b4c44c89657e927be935db0",
            "11b449ff61b042ac8459dae786abd71c",
            "8494f14d69f04423bacbb85c752c2000",
            "8c851b2245ec4a36a831f15e01495ced",
            "2f32fada4a8040cdaac7a45627391c91",
            "8728206835f84335bd48e562bdcaeaee",
            "67e2ede5e2d742b28549ff1a7810f382",
            "4d1b4afd11584ef9a5c4629794231101",
            "36a6ba32b73f423d9c8d95c8f670ce1e",
            "083e07d00ee34b899441a3b301342f08",
            "de5e1dbe86dc4722bb3164e15ed00b30",
            "55f173c83fcb4bbe838d2bf26527ed9a",
            "49202a3183c14b9ca7467ce866055db0",
            "8fc9a724f01246b09f18a606beba8703",
            "0d7c3c43a79a4244a7d21181430e272e",
            "630746e51eaa4667acc616ae066465b9",
            "c44e14c1b2de428fbf2d517bd1edebc7",
            "833a17c608104c2b823eb6791819e242",
            "ad65ed77bc154f6bb7746a9701659665",
            "cfcb3fb3c0bb4fc7831f2143fe4b0728",
            "96f8c95c8e3848c9b9cad8b2b9ebad8a",
            "f7d481ad0e7a4bd9a1f86dec3ecb0479",
            "b704c5871fd349cda4c1a062d598fff9"
          ]
        },
        "id": "FSPJ3q5xSt7W",
        "outputId": "f94e85d1-d526-409f-ec40-52dfabc3f0ab",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T08:37:43.194908Z",
          "iopub.execute_input": "2025-01-16T08:37:43.195230Z",
          "iopub.status.idle": "2025-01-16T08:37:58.313656Z",
          "shell.execute_reply.started": "2025-01-16T08:37:43.195204Z",
          "shell.execute_reply": "2025-01-16T08:37:58.312774Z"
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/19072 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7d481ad0e7a4bd9a1f86dec3ecb0479"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/509 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b704c5871fd349cda4c1a062d598fff9"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Choose your model"
      ],
      "metadata": {
        "id": "2XM5OsV_Yllm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(data[label].unique()))\n",
        "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(data[label].unique()), ignore_mismatched_sizes=True)\n",
        "model.to('cuda')  # Move model to GPU if available"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958,
          "referenced_widgets": [
            "52cc9c0d5ea044a08b98b4478532b482",
            "e81776dcbc8f4c8b9eff76ddb5578c72",
            "5f843d7b98f54d13ab9fa61fb03fd5b2",
            "d343b5e26bc5453c80430ba3520794e1",
            "3f9de437528741b5bcea6257d48d629f",
            "d1e22564cb39434cabd557c547db49fb",
            "b400753b3ca74e58be712eceaff4e33c",
            "42e8f9b5629e4dbcabeffb1211f367b2",
            "016e389c87574837990ba6007d57e28c",
            "ac29d3acc38e48acbc44a6644a018e32",
            "7281d98b82fb47d892b3810aba0c8f17",
            "5b709f12bab5448a862d5701c85e6d1d",
            "2c5e3855b87344aeaed42558558ae34f",
            "c9394f129d5d495cb6f7e990aa37dada",
            "0b0e245722804685b066d442801d8feb",
            "2bfa6dfe29634e598949116a54666a5c",
            "a73ba9f383c34eddae1226cc2bcc4106",
            "9cca96b859f341bdbeac80b728eed320",
            "ea35d79ead4b4899b7ef1884cdc46544",
            "c2c55ac403e347e5a63e7f8ad2d1d78a",
            "60056fb76eb94e38b311e42bd82dd19c",
            "8df8a25a55d04378800436c7821e7801"
          ]
        },
        "id": "OF9RyTv9SyuW",
        "outputId": "006a8eaa-2999-404c-9aca-b44af449d3aa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T08:38:02.082254Z",
          "iopub.execute_input": "2025-01-16T08:38:02.082561Z",
          "iopub.status.idle": "2025-01-16T08:38:02.951877Z",
          "shell.execute_reply.started": "2025-01-16T08:38:02.082539Z",
          "shell.execute_reply": "2025-01-16T08:38:02.951158Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "execution_count": 26,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=10, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Train it"
      ],
      "metadata": {
        "id": "CsP__kiFYoXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "num_epochs = 5\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "\n",
        "model.train()\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to('cuda') for k, v in batch.items()}  # Move batch to GPU if available\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140,
          "referenced_widgets": [
            "f56d659f41bf4583ba5fce28a61d51e4",
            "5d77334fc5eb469d98e7a4f397c0d568",
            "be5a8b40df3948c98bc1690780804266",
            "8f9b2080dbc34bd6be6f36c44d9b1afc",
            "c58f6ef7f9824805a4c774fa87532a59",
            "b9f63fa3ee4d441ca5b7aaa87aa60730",
            "51360b7443d0487aa852d2bc0ce1e044",
            "fc3363e1c56e4f518df848f4ed59e490",
            "747bcacff49841c9bd87303602192f1c",
            "455b116f5dd044c3874dc0edcc990067",
            "c50ca5f30ae04abf86eb4bfbad9555d3",
            "c1ebae078afd4030aab7720567f10d2e"
          ]
        },
        "id": "oflgiPlUTGVN",
        "outputId": "acd7a532-085a-4159-9dcf-3f4b65278454",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T08:38:07.817423Z",
          "iopub.execute_input": "2025-01-16T08:38:07.817745Z",
          "iopub.status.idle": "2025-01-16T09:58:02.515493Z",
          "shell.execute_reply.started": "2025-01-16T08:38:07.817715Z",
          "shell.execute_reply": "2025-01-16T09:58:02.514774Z"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/11920 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1ebae078afd4030aab7720567f10d2e"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2888: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Assess it"
      ],
      "metadata": {
        "id": "Y7KNZ5vqYpu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = BertForSequenceClassification.from_pretrained(\"/content/drive/My Drive/FoodHazardData/bert_hazard_category\")\n",
        "\n",
        "# # Move model to GPU if available\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)\n",
        "\n",
        "model.eval()\n",
        "total_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        batch = {k: v.to('cuda') for k, v in batch.items()}  # Move batch to GPU if available\n",
        "        outputs = model(**batch)\n",
        "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "        total_predictions.extend([p.item() for p in predictions])\n",
        "\n",
        "#print(classification_report(test_df.label, total_predictions))\n",
        "predicted_labels = label_encoder.inverse_transform(total_predictions)\n",
        "gold_labels = label_encoder.inverse_transform(test_df.label.values)\n",
        "print(classification_report(gold_labels, predicted_labels, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "morbg_D9VmSb",
        "outputId": "0340c64d-47a8-4c39-9dfb-ef8f03128afb",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T09:59:50.365760Z",
          "iopub.execute_input": "2025-01-16T09:59:50.366061Z",
          "iopub.status.idle": "2025-01-16T09:59:58.791481Z",
          "shell.execute_reply.started": "2025-01-16T09:59:50.366040Z",
          "shell.execute_reply": "2025-01-16T09:59:58.790573Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                                precision    recall  f1-score   support\n\n                     allergens       0.98      0.99      0.99       188\n                    biological       0.99      0.99      0.99       171\n                      chemical       1.00      0.97      0.99        35\nfood additives and flavourings       1.00      1.00      1.00         5\n                foreign bodies       0.97      1.00      0.98        58\n                         fraud       0.93      0.89      0.91        28\n                     migration       1.00      1.00      1.00         1\n          organoleptic aspects       0.75      1.00      0.86         3\n                  other hazard       0.86      0.80      0.83        15\n              packaging defect       1.00      1.00      1.00         5\n\n                      accuracy                           0.98       509\n                     macro avg       0.95      0.96      0.95       509\n                  weighted avg       0.98      0.98      0.98       509\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"distilbert_hazard_category_gemini_nlp\")\n",
        "# model.save_pretrained(\"/content/drive/My Drive/FoodHazardData/Models/bert_hazard_category_gemini_pubmed\")"
      ],
      "metadata": {
        "id": "NxL43TP9IAw4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T10:00:33.439789Z",
          "iopub.execute_input": "2025-01-16T10:00:33.440093Z",
          "iopub.status.idle": "2025-01-16T10:00:34.339990Z",
          "shell.execute_reply.started": "2025-01-16T10:00:33.440064Z",
          "shell.execute_reply": "2025-01-16T10:00:34.339058Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T10:01:58.057898Z",
          "iopub.execute_input": "2025-01-16T10:01:58.058205Z",
          "iopub.status.idle": "2025-01-16T10:01:58.061751Z",
          "shell.execute_reply.started": "2025-01-16T10:01:58.058182Z",
          "shell.execute_reply": "2025-01-16T10:01:58.061045Z"
        },
        "id": "KewO6Lkr5KNp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-16T10:02:18.209385Z",
          "iopub.execute_input": "2025-01-16T10:02:18.209706Z",
          "iopub.status.idle": "2025-01-16T10:02:18.244932Z",
          "shell.execute_reply.started": "2025-01-16T10:02:18.209678Z",
          "shell.execute_reply": "2025-01-16T10:02:18.243809Z"
        },
        "id": "Vkz1hupP5KNp",
        "outputId": "b7e88d71-1d60-4ece-b5ad-11cb702d2e0e"
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-3b8a479202a4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    116\u001b[0m   \u001b[0;34m\"\"\"Internal helper to mount Google Drive.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/var/colab/hostname'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     raise NotImplementedError(\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;34m'Mounting drive is unsupported in this environment. Use PyDrive'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;34m' instead. See examples at'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Mounting drive is unsupported in this environment. Use PyDrive instead. See examples at https://colab.research.google.com/notebooks/io.ipynb#scrollTo=7taylj9wpsA2."
          ],
          "ename": "NotImplementedError",
          "evalue": "Mounting drive is unsupported in this environment. Use PyDrive instead. See examples at https://colab.research.google.com/notebooks/io.ipynb#scrollTo=7taylj9wpsA2.",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# List of model paths saved in Google Drive\n",
        "model_paths = [\n",
        "    \"/content/drive/My Drive/FoodHazardData/bert_hazard_category\",\n",
        "    \"/content/drive/My Drive/FoodHazardData/Models/bert_hazard_category_gemini\",\n",
        "    # \"/content/drive/My Drive/FoodHazardData/bert_hazard_category_model_3\"\n",
        "]\n",
        "\n",
        "# Load all models\n",
        "models = []\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for path in model_paths:\n",
        "    model = BertForSequenceClassification.from_pretrained(path)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    models.append(model)\n",
        "\n",
        "# Evaluate with ensembling\n",
        "total_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        # Move batch to GPU if available\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "        # Get logits from all models\n",
        "        logits_list = []\n",
        "        for model in models:\n",
        "            outputs = model(**batch)\n",
        "            logits_list.append(outputs.logits.cpu().numpy())\n",
        "\n",
        "        # Ensemble predictions by averaging logits\n",
        "        avg_logits = np.mean(logits_list, axis=0)  # Average logits from all models\n",
        "\n",
        "        # Get final predictions by taking the argmax of averaged logits\n",
        "        predictions = np.argmax(avg_logits, axis=-1)\n",
        "        total_predictions.extend(predictions)\n",
        "\n",
        "# Decode predicted labels and gold labels\n",
        "predicted_labels = label_encoder.inverse_transform(total_predictions)\n",
        "gold_labels = label_encoder.inverse_transform(test_df.label.values)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(gold_labels, predicted_labels, zero_division=0))\n"
      ],
      "metadata": {
        "id": "uHpVehDQeL-_",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label: `Product Category`"
      ],
      "metadata": {
        "id": "-Q_9l5oMWxA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = 'product-category'\n",
        "label_encoder = LabelEncoder()\n",
        "data['label'] = label_encoder.fit_transform(data[label])\n",
        "synthesized_df['label'] = label_encoder.transform(synthesized_df[label])\n",
        "\n",
        "with open(f'{label}_label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoder, f)"
      ],
      "metadata": {
        "id": "CEBGFceL9rFP",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(data, test_size=0.1, random_state=42)\n",
        "train_df = pd.concat([train_df, synthesized_df], ignore_index=True)\n",
        "train_df['product-category'].value_counts()"
      ],
      "metadata": {
        "id": "uHuBaF8lTJHn",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# ----------------------------\n",
        "# 1. Synonym Replacement Functions\n",
        "# ----------------------------\n",
        "def get_synonyms(word):\n",
        "    \"\"\"Retrieve synonyms for a given word using WordNet.\"\"\"\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonym = lemma.name().replace('_', ' ').lower()\n",
        "            if synonym != word.lower():\n",
        "                synonyms.add(synonym)\n",
        "    return list(synonyms)\n",
        "\n",
        "def synonym_replacement(sentence, n=1):\n",
        "    \"\"\"\n",
        "    Replace up to n words in the sentence with their synonyms.\n",
        "\n",
        "    Args:\n",
        "        sentence (str): The original sentence.\n",
        "        n (int): Number of words to replace.\n",
        "\n",
        "    Returns:\n",
        "        str: The augmented sentence.\n",
        "    \"\"\"\n",
        "    words = sentence.split()\n",
        "    new_words = words.copy()\n",
        "    eligible_words = [word for word in words if word.isalpha()]\n",
        "    random.shuffle(eligible_words)\n",
        "    num_replaced = 0\n",
        "\n",
        "    for random_word in eligible_words:\n",
        "        synonyms = get_synonyms(random_word)\n",
        "        if synonyms:\n",
        "            synonym = random.choice(synonyms)\n",
        "            new_words = [synonym if word == random_word else word for word in new_words]\n",
        "            num_replaced += 1\n",
        "        if num_replaced >= n:\n",
        "            break\n",
        "\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Data Splitting\n",
        "# ----------------------------\n",
        "# Split the data into training and testing sets\n",
        "train_df, test_df = train_test_split(data, test_size=0.1, random_state=42)\n",
        "train_df = pd.concat([train_df, synthesized_df], ignore_index=True)\n",
        "\n",
        "# ----------------------------\n",
        "# 3. Augment the Training Data\n",
        "# ----------------------------\n",
        "# augmented_data = []\n",
        "\n",
        "# # 3a. Class counts and thresholds for augmentation\n",
        "# class_counts = train_df['product-category'].value_counts()\n",
        "# minority_threshold = 351   # Classes below this threshold will be augmented\n",
        "# augmentations_per_class = 150  # Number of new samples to add for any minority class\n",
        "# minimum_class_size = 150   # Ensure each class is at least this big if it's too small\n",
        "# minority_classes = class_counts[class_counts < minority_threshold].index.tolist()\n",
        "\n",
        "# # ----------------------------\n",
        "# # 3b. Define a helper for augmentation\n",
        "# # ----------------------------\n",
        "# def augment_class_data(class_df, target_total):\n",
        "#     \"\"\"\n",
        "#     Augment `class_df` until its total size (original + new) is `target_total`.\n",
        "#     Distribute augmentations across existing rows.\n",
        "#     \"\"\"\n",
        "#     augmented_rows = []\n",
        "#     current_count = len(class_df)\n",
        "#     # How many new samples do we need?\n",
        "#     additional_needed = target_total - current_count\n",
        "#     if additional_needed <= 0:\n",
        "#         return []  # No augmentation needed\n",
        "\n",
        "#     # Distribute 'additional_needed' among the existing samples\n",
        "#     times_each = additional_needed // current_count\n",
        "#     remainder = additional_needed % current_count\n",
        "\n",
        "#     # Shuffle indices for distributing that remainder randomly\n",
        "#     indices = class_df.index.tolist()\n",
        "#     random.shuffle(indices)\n",
        "\n",
        "#     # For each row in the class, augment it 'times_each' times,\n",
        "#     # plus 1 extra if you're within the remainder range.\n",
        "#     for i, row_idx in enumerate(indices):\n",
        "#         row = class_df.loc[row_idx]\n",
        "#         # Determine how many times this row will be augmented\n",
        "#         n_augmentations = times_each + (1 if i < remainder else 0)\n",
        "\n",
        "#         for _ in range(n_augmentations):\n",
        "#             # You can tune n=2, n=10, etc. for the number of words replaced\n",
        "#             augmented_title_text = synonym_replacement(row['title_text'], n=2)\n",
        "#             # augmented_text = synonym_replacement(row['text'], n=2)  # If you want to augment the other field too\n",
        "\n",
        "#             new_row = row.copy()\n",
        "#             new_row['title_text'] = augmented_title_text\n",
        "#             # new_row['text'] = augmented_text\n",
        "#             augmented_rows.append(new_row)\n",
        "\n",
        "#     return augmented_rows\n",
        "\n",
        "# # ----------------------------\n",
        "# # 3c. Augment each minority class\n",
        "# # ----------------------------\n",
        "# for minority_class in minority_classes:\n",
        "#     print(f\"Augmenting class '{minority_class}'\")\n",
        "#     class_data = train_df[train_df['product-category'] == minority_class]\n",
        "\n",
        "#     # 1) First, if it has fewer than 150 samples, bring it up to 150\n",
        "#     if len(class_data) < minimum_class_size:\n",
        "#         to_150 = augment_class_data(class_data, target_total=minimum_class_size)\n",
        "#         augmented_data.extend(to_150)\n",
        "#         # Update the class_data to include newly augmented rows so total goes up to 150\n",
        "#         if to_150:\n",
        "#             new_df = pd.DataFrame(to_150)\n",
        "#             class_data = pd.concat([class_data, new_df], ignore_index=True)\n",
        "\n",
        "#     # 2) Now, add an extra 'augmentations_per_class' beyond the *new* count\n",
        "#     updated_count = len(class_data)\n",
        "#     final_target = updated_count + augmentations_per_class\n",
        "#     additional_aug = augment_class_data(class_data, target_total=final_target)\n",
        "#     augmented_data.extend(additional_aug)\n",
        "\n",
        "# # ----------------------------\n",
        "# # 3d. Combine everything\n",
        "# # ----------------------------\n",
        "# augmented_df = pd.DataFrame(augmented_data)\n",
        "# train_df = pd.concat([train_df, augmented_df], ignore_index=True)\n",
        "print(f\"Final augmented training set size: {len(train_df)}\")\n",
        "train_df['product-category'].value_counts()"
      ],
      "metadata": {
        "id": "rxDOc_wTyhAA",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "# train_df, test_df = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert DataFrame to Hugging Face Dataset\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Apply the tokenizer to the dataset\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Create DataCollator to handle padding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True, max_length=16)\n",
        "\n",
        "# Convert dataset to PyTorch format\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# Create DataLoader objects\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=8, collate_fn=data_collator)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=8, collate_fn=data_collator)"
      ],
      "metadata": {
        "id": "9hv5Z7-BVc-4",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Train"
      ],
      "metadata": {
        "id": "3Q4vN1I0X88D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_product_category = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(data[label].unique()))\n",
        "model_product_category = AutoModelForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=len(data[label].unique()))\n",
        "model_product_category.to('cuda')  # Move model to GPU if available\n",
        "\n",
        "optimizer = AdamW(model_product_category.parameters(), lr=5e-5)\n",
        "num_epochs = 5\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "\n",
        "model_product_category.train()\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to('cuda') for k, v in batch.items()}  # Move batch to GPU if available\n",
        "        outputs = model_product_category(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)"
      ],
      "metadata": {
        "id": "DQVDnd4SXedT",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# model_product_category = BertForSequenceClassification.from_pretrained(\"/content/drive/My Drive/FoodHazardData/bert_product_category\")\n",
        "\n",
        "# Move model to GPU if available\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model_product_category.to(device)\n",
        "\n",
        "model_product_category.eval()\n",
        "total_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        batch = {k: v.to('cuda') for k, v in batch.items()}  # Move batch to GPU if available\n",
        "        outputs = model_product_category(**batch)\n",
        "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "        total_predictions.extend([p.item() for p in predictions])\n",
        "\n",
        "#print(classification_report(test_df.label, total_predictions, zero_division=0))\n",
        "predicted_labels = label_encoder.inverse_transform(total_predictions)\n",
        "gold_labels = label_encoder.inverse_transform(test_df.label.values)\n",
        "print(classification_report(gold_labels, predicted_labels, zero_division=0))"
      ],
      "metadata": {
        "id": "TMh_X_AeUOOl",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Test"
      ],
      "metadata": {
        "id": "ZRivrfVuX_Nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_product_category.save_pretrained(\"bert_product_category_gemini\")\n",
        "model_product_category.save_pretrained(\"/content/drive/My Drive/FoodHazardData/Models/bert_product_category_gemini\")"
      ],
      "metadata": {
        "id": "tB9_Ewr4H5Jx",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label: `Hazard`"
      ],
      "metadata": {
        "id": "d_8B_Wo0Y4b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = 'hazard'\n",
        "label_encoder = LabelEncoder()\n",
        "data['label'] = label_encoder.fit_transform(data[label])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_df, test_df = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert DataFrame to Hugging Face Dataset\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Apply the tokenizer to the dataset\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Create DataCollator to handle padding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True, max_length=16)\n",
        "\n",
        "# Convert dataset to PyTorch format\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# Create DataLoader objects\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=8, collate_fn=data_collator)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=8, collate_fn=data_collator)"
      ],
      "metadata": {
        "id": "UqkSg1omYK30",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_hazard = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(data[label].unique()))\n",
        "model_hazard.to('cuda')  # Move model to GPU if available\n",
        "\n",
        "optimizer = AdamW(model_hazard.parameters(), lr=5e-5)\n",
        "\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "\n",
        "model_hazard.train()\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to('cuda') for k, v in batch.items()}  # Move batch to GPU if available\n",
        "        outputs = model_hazard(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)"
      ],
      "metadata": {
        "id": "qDyieqiiY94T",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_hazard.eval()\n",
        "total_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        batch = {k: v.to('cuda') for k, v in batch.items()}  # Move batch to GPU if available\n",
        "        outputs = model_hazard(**batch)\n",
        "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "        total_predictions.extend([p.item() for p in predictions])\n",
        "\n",
        "#print(classification_report(test_df.label, total_predictions, zero_division=0))\n",
        "predicted_labels = label_encoder.inverse_transform(total_predictions)\n",
        "gold_labels = label_encoder.inverse_transform(test_df.label.values)\n",
        "print(classification_report(gold_labels, predicted_labels, zero_division=0))"
      ],
      "metadata": {
        "id": "7jbEizzfZHle",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_hazard.save_pretrained(\"bert_hazard\")"
      ],
      "metadata": {
        "id": "rWPiviPlHxvr",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label: `product`"
      ],
      "metadata": {
        "id": "uFjG06XBZWCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = 'product'\n",
        "label_encoder = LabelEncoder()\n",
        "data['label'] = label_encoder.fit_transform(data[label])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_df, test_df = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert DataFrame to Hugging Face Dataset\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Apply the tokenizer to the dataset\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Create DataCollator to handle padding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True, max_length=16)\n",
        "\n",
        "# Convert dataset to PyTorch format\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# Create DataLoader objects\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=8, collate_fn=data_collator)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=8, collate_fn=data_collator)"
      ],
      "metadata": {
        "id": "ZND1Vb6fZVSg",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_product = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(data[label].unique()))\n",
        "model_product.to('cuda')  # Move model to GPU if available\n",
        "\n",
        "optimizer = AdamW(model_product.parameters(), lr=5e-5)\n",
        "num_epochs = 3\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "model_product.train()\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to('cuda') for k, v in batch.items()}  # Move batch to GPU if available\n",
        "        outputs = model_product(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)"
      ],
      "metadata": {
        "id": "UzOywpcMZfm5",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_product.eval()\n",
        "total_predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        batch = {k: v.to('cuda') for k, v in batch.items()}  # Move batch to GPU if available\n",
        "        outputs = model_product(**batch)\n",
        "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "        total_predictions.extend([p.item() for p in predictions])\n",
        "\n",
        "#print(classification_report(test_df.label, total_predictions, zero_division=0))\n",
        "predicted_labels = label_encoder.inverse_transform(total_predictions)\n",
        "gold_labels = label_encoder.inverse_transform(test_df.label.values)\n",
        "print(classification_report(gold_labels, predicted_labels, zero_division=0))"
      ],
      "metadata": {
        "id": "BDnC9FVTZqWt",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_product.save_pretrained(\"bert_product\")\n",
        "tokenizer.save_pretrained(\"bert_tokenizer\")"
      ],
      "metadata": {
        "id": "maGolSynFapV",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!zip bert_baseline.zip bert_*"
      ],
      "metadata": {
        "id": "AcMVpk-FHtuK",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading a trained baseline"
      ],
      "metadata": {
        "id": "of2EPdkmIzhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "def predict(texts, model_path, tokenizer_path=\"tokenizer\", batch_size=32):\n",
        "    # Load the saved tokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "    # Load the saved model\n",
        "    model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "    # Move model to GPU if available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Tokenize the input texts\n",
        "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    # Move inputs to the same device as the model\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Make predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "        # for batch in test_dataloader:\n",
        "        #   batch = {k: v.to('cuda') for k, v in batch.items()}  # Move batch to GPU if available\n",
        "        #   outputs = model(**batch)\n",
        "        #   predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "        #   total_predictions.extend([p.item() for p in predictions])\n",
        "\n",
        "    return predictions.cpu().numpy().tolist()\n",
        "\n",
        "    # Initialize an empty list to store predictions\n",
        "    # all_predictions = []\n",
        "\n",
        "    # # Process texts in batches\n",
        "    # for i in range(0, len(texts), batch_size):\n",
        "    #     batch_texts = texts[i:i + batch_size]  # Create a batch of texts\n",
        "\n",
        "    #     # Tokenize the input texts for the current batch\n",
        "    #     inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "    #     # Move inputs to the same device as the model\n",
        "    #     inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    #     # Make predictions for the batch\n",
        "    #     with torch.no_grad():\n",
        "    #         outputs = model(**inputs)\n",
        "    #         logits = outputs.logits\n",
        "    #         predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "    #     # Collect predictions from the current batch\n",
        "    #     all_predictions.extend(predictions.cpu().numpy().tolist())\n",
        "\n",
        "    # return all_predictions"
      ],
      "metadata": {
        "id": "HBgUSxhPIWaA",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def compute_score(hazards_true, products_true, hazards_pred, products_pred):\n",
        "  # Convert string labels to numerical labels for hazards\n",
        "  le_hazards = LabelEncoder()\n",
        "  hazards_true = le_hazards.fit_transform(hazards_true)\n",
        "\n",
        "  # compute f1 for hazards:\n",
        "  f1_hazards = f1_score(\n",
        "    hazards_true,\n",
        "    hazards_pred,\n",
        "    average='macro'\n",
        "  )\n",
        "\n",
        "  # Convert string labels to numerical labels for products\n",
        "  le_products = LabelEncoder()\n",
        "  products_true = le_products.fit_transform(products_true)\n",
        "\n",
        "  # compute f1 for products:\n",
        "  f1_products = f1_score(\n",
        "    products_true[hazards_pred == hazards_true],\n",
        "    products_pred[hazards_pred == hazards_true],\n",
        "    average='macro'\n",
        "  )\n",
        "\n",
        "  return (f1_hazards + f1_products) / 2."
      ],
      "metadata": {
        "id": "sumw9iLwKK_w",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pd.DataFrame()"
      ],
      "metadata": {
        "id": "lhrDR6y_4r_n",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sub-Task 1:"
      ],
      "metadata": {
        "id": "OJjb_aV8eQUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Load the pre-fitted LabelEncoders\n",
        "hazard_label_encoder = joblib.load(\"hazard-category_label_encoder.pkl\")\n",
        "product_label_encoder = joblib.load(\"product-category_label_encoder.pkl\")\n",
        "\n",
        "# Store them in a dictionary for easier access if needed\n",
        "label_encoders = {\n",
        "    \"hazard_category\": hazard_label_encoder,\n",
        "    \"product_category\": product_label_encoder\n",
        "}"
      ],
      "metadata": {
        "id": "gxb-83fFBHEY",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for category in ['hazard_category', 'product_category']: #, 'hazard', 'product']:\n",
        "# for category in ['product_category']:\n",
        "  c = category.replace('_', '-')\n",
        "  print(c.upper())\n",
        "  predictions[category] = predict(test_df.title_text.to_list(), f\"/content/drive/My Drive/FoodHazardData/bert_{category}\")\n",
        "  # Decode predictions back to string labels\n",
        "  label_encoder = label_encoders[category]\n",
        "  gold = label_encoder.fit_transform(test_df[c])\n",
        "  print(classification_report(gold, predictions[category], zero_division=0))"
      ],
      "metadata": {
        "id": "t8l2GeQAd8z6",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Score Sub-Task 1: {compute_score(test_df['hazard-category'], test_df['product-category'], predictions['hazard_category'], predictions['product_category']):.3f}\")\n",
        "# print(f\"Score Sub-Task 2: {compute_score(test_df['hazard'], test_df['product'], predictions['hazard'], predictions['product']):.3f}\")"
      ],
      "metadata": {
        "id": "FOH5HX07KBXH",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "train_df, test_df = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert DataFrame to Hugging Face Dataset\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Apply the tokenizer to the dataset\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Create DataCollator to handle padding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True, max_length=16)\n",
        "\n",
        "# Convert dataset to PyTorch format\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# Create DataLoader objects\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=8, collate_fn=data_collator)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=8, collate_fn=data_collator)"
      ],
      "metadata": {
        "id": "GgTpFca3Euic",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "PkRgo9xV0kVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from datasets import Dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "\n",
        "# Load validation data\n",
        "validation_data = pd.read_csv('/content/drive/My Drive/FoodHazardData/incidents_validation.csv', index_col=0)\n",
        "\n",
        "# Combine title and text for predictions\n",
        "validation_data['title_text'] = validation_data['title'] + ' ' + validation_data['text']\n",
        "\n",
        "# Function to tokenize input\n",
        "def tokenize_function(examples, tokenizer):\n",
        "    return tokenizer(examples['title_text'], padding=True, truncation=True)\n",
        "\n",
        "# Function to load model and make predictions\n",
        "def predict_category(model_path, tokenizer_path, label_encoder_path, validation_data):\n",
        "    # Load tokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "    # Tokenize validation data\n",
        "    dataset = Dataset.from_pandas(validation_data)\n",
        "    dataset = dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n",
        "\n",
        "    # Format dataset for PyTorch\n",
        "    dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=8)\n",
        "\n",
        "    # Load model\n",
        "    model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Load label encoder\n",
        "    with open(label_encoder_path, 'rb') as f:\n",
        "        label_encoder = pickle.load(f)\n",
        "\n",
        "    # Make predictions\n",
        "    total_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "            total_predictions.extend([p.item() for p in predictions])\n",
        "\n",
        "    # Decode predictions\n",
        "    predicted_labels = label_encoder.inverse_transform(total_predictions)\n",
        "    return predicted_labels\n",
        "\n",
        "# Paths for hazard-category model, tokenizer, and label encoder\n",
        "hazard_model_path = \"/content/drive/My Drive/FoodHazardData/bert_hazard_category\"\n",
        "hazard_tokenizer_path = \"tokenizer\"\n",
        "hazard_label_encoder_path = \"hazard-category_label_encoder.pkl\"\n",
        "\n",
        "# Predict hazard-category\n",
        "validation_data['hazard-category'] = predict_category(\n",
        "    hazard_model_path,\n",
        "    hazard_tokenizer_path,\n",
        "    hazard_label_encoder_path,\n",
        "    validation_data\n",
        ")\n",
        "\n",
        "# Combine hazard-category with title and text for product-category prediction\n",
        "validation_data['title_text'] = 'Hazard Category: ' + validation_data['hazard-category'] + ' ' + validation_data['title'] + ' ' + validation_data['text']\n",
        "\n",
        "# Paths for product-category model, tokenizer, and label encoder\n",
        "product_model_path = \"/content/drive/My Drive/FoodHazardData/Models/bert_product_category_gemini\"\n",
        "product_tokenizer_path = \"tokenizer\"\n",
        "product_label_encoder_path = \"product-category_label_encoder.pkl\"\n",
        "\n",
        "# Predict product-category\n",
        "validation_data['product-category'] = predict_category(\n",
        "    product_model_path,\n",
        "    product_tokenizer_path,\n",
        "    product_label_encoder_path,\n",
        "    validation_data\n",
        ")\n",
        "\n",
        "# Save to submission.csv\n",
        "submission = validation_data[['hazard-category', 'product-category']]\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved to 'submission.csv'\")\n"
      ],
      "metadata": {
        "id": "zVtqk_t_Njy8",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# download submission as csv\n",
        "from google.colab import files\n",
        "files.download('submission.csv')"
      ],
      "metadata": {
        "id": "j9nmGW34ugkQ",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from datasets import Dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('food-hazard-detection-semeval-2025.github.io/data/incidents_train.csv', index_col=0)\n",
        "\n",
        "# Split data into train and test sets\n",
        "train_df, test_df = train_test_split(data, test_size=0.1, random_state=42)\n",
        "\n",
        "# Combine title and text for predictions in test set\n",
        "test_df['title_text'] = test_df['title'] + ' ' + test_df['text']\n",
        "\n",
        "# Function to tokenize input\n",
        "def tokenize_function(examples, tokenizer):\n",
        "    return tokenizer(examples['title_text'], padding=True, truncation=True)\n",
        "\n",
        "# Function to load model and make predictions\n",
        "def predict_category(model_path, tokenizer_path, label_encoder_path, validation_data):\n",
        "    # Load tokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "    # Tokenize validation data\n",
        "    dataset = Dataset.from_pandas(validation_data)\n",
        "    dataset = dataset.map(lambda x: tokenize_function(x, tokenizer), batched=True)\n",
        "\n",
        "    # Format dataset for PyTorch\n",
        "    dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=8)\n",
        "\n",
        "    # Load model\n",
        "    model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Load label encoder\n",
        "    with open(label_encoder_path, 'rb') as f:\n",
        "        label_encoder = pickle.load(f)\n",
        "\n",
        "    # Make predictions\n",
        "    total_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "            total_predictions.extend([p.item() for p in predictions])\n",
        "\n",
        "    # Decode predictions\n",
        "    predicted_labels = label_encoder.inverse_transform(total_predictions)\n",
        "    return predicted_labels\n",
        "\n",
        "# Paths for hazard-category model, tokenizer, and label encoder\n",
        "hazard_model_path = \"/content/drive/My Drive/FoodHazardData/bert_hazard_categoryf\"\n",
        "hazard_tokenizer_path = \"tokenizer\"\n",
        "hazard_label_encoder_path = \"hazard-category_label_encoder.pkl\"\n",
        "\n",
        "# Predict hazard-category\n",
        "test_df['hazard-category-pred'] = predict_category(\n",
        "    hazard_model_path,\n",
        "    hazard_tokenizer_path,\n",
        "    hazard_label_encoder_path,\n",
        "    test_df\n",
        ")\n",
        "\n",
        "# Combine hazard-category with title and text for product-category prediction\n",
        "test_df['title_text'] = 'Hazard Category: ' + test_df['hazard-category'] + ' ' + test_df['title'] + ' ' + test_df['text']\n",
        "\n",
        "# Paths for product-category model, tokenizer, and label encoder\n",
        "product_model_path = \"/content/drive/My Drive/FoodHazardData/bert_product_category3\"\n",
        "product_tokenizer_path = \"tokenizer\"\n",
        "product_label_encoder_path = \"product-category_label_encoder.pkl\"\n",
        "\n",
        "# Predict product-category\n",
        "test_df['product-category-pred'] = predict_category(\n",
        "    product_model_path,\n",
        "    product_tokenizer_path,\n",
        "    product_label_encoder_path,\n",
        "    test_df\n",
        ")\n",
        "\n",
        "# Compute classification report and final score\n",
        "def compute_score(hazards_true, products_true, hazards_pred, products_pred):\n",
        "    # Compute F1 for hazards\n",
        "    f1_hazards = f1_score(hazards_true, hazards_pred, average='macro')\n",
        "\n",
        "    # Compute F1 for products (only for correctly predicted hazards)\n",
        "    correct_hazards = hazards_true == hazards_pred\n",
        "    f1_products = f1_score(\n",
        "        products_true[correct_hazards],\n",
        "        products_pred[correct_hazards],\n",
        "        average='macro'\n",
        "    )\n",
        "\n",
        "    return (f1_hazards + f1_products) / 2\n",
        "\n",
        "# Extract true and predicted labels\n",
        "hazards_true = test_df['hazard-category']\n",
        "products_true = test_df['product-category']\n",
        "hazards_pred = test_df['hazard-category-pred']\n",
        "products_pred = test_df['product-category-pred']\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report for Hazard-Category:\")\n",
        "print(classification_report(hazards_true, hazards_pred))\n",
        "\n",
        "print(\"Classification Report for Product-Category (correct hazards only):\")\n",
        "correct_hazards = hazards_true == hazards_pred\n",
        "print(classification_report(products_true[correct_hazards], products_pred[correct_hazards]))\n",
        "\n",
        "# Compute final score\n",
        "final_score = compute_score(hazards_true, products_true, hazards_pred, products_pred)\n",
        "print(f\"Final Score: {final_score}\")\n"
      ],
      "metadata": {
        "id": "TYo50A17p6fj",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def compute_score(hazards_true, products_true, hazards_pred, products_pred):\n",
        "    \"\"\"\n",
        "    Computes the macro-F1 for hazards, then the macro-F1 for products\n",
        "    *only for rows where hazards_pred == hazards_true*.\n",
        "    Finally returns the average of those two scores.\n",
        "    \"\"\"\n",
        "    # -- F1 for hazards (macro) --\n",
        "    f1_hazards = f1_score(hazards_true, hazards_pred, average='macro')\n",
        "\n",
        "    # -- F1 for products, only on rows where hazard is correct --\n",
        "    correct_hazard_mask = (hazards_pred == hazards_true)\n",
        "    # If no hazards were correct, this can raise an error.\n",
        "    # For safety, you might do a check to handle that edge case.\n",
        "    f1_products = f1_score(\n",
        "        products_true[correct_hazard_mask],\n",
        "        products_pred[correct_hazard_mask],\n",
        "        average='macro'\n",
        "    )\n",
        "\n",
        "    return (f1_hazards + f1_products) / 2.0\n",
        "\n",
        "# -----------------------------\n",
        "# 1. Read the ground truth\n",
        "# -----------------------------\n",
        "df_valid = pd.read_csv(\"incidents_valid.csv\")\n",
        "\n",
        "# We only need these columns from the ground truth\n",
        "df_valid = df_valid[[\"hazard-category\", \"product-category\"]].copy()\n",
        "df_valid.columns = [\"hazard_true\", \"product_true\"]\n",
        "\n",
        "# -----------------------------\n",
        "# 2. Read your submission\n",
        "# -----------------------------\n",
        "df_sub = pd.read_csv(\"submission.csv\")\n",
        "\n",
        "# We only need these columns from the submission\n",
        "df_sub = df_sub[[\"hazard-category\", \"product-category\"]].copy()\n",
        "df_sub.columns = [\"hazard_pred\", \"product_pred\"]\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Concatenate or merge to compare row by row\n",
        "# -----------------------------\n",
        "# *** IMPORTANT ***\n",
        "# This assumes that the number of rows in df_valid\n",
        "# and df_sub match, and that each row corresponds\n",
        "# to the same incident.\n",
        "df_compare = pd.concat([df_valid, df_sub], axis=1)\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Compute final score\n",
        "# -----------------------------\n",
        "score = compute_score(\n",
        "    hazards_true=df_compare[\"hazard_true\"],\n",
        "    products_true=df_compare[\"product_true\"],\n",
        "    hazards_pred=df_compare[\"hazard_pred\"],\n",
        "    products_pred=df_compare[\"product_pred\"]\n",
        ")\n",
        "\n",
        "print(\"Your macro-F1 Score (with the given formula) =\", score)\n"
      ],
      "metadata": {
        "id": "On3hY9U4dfwZ",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from shutil import make_archive\n",
        "\n",
        "# save predictions to a new folder:\n",
        "os.makedirs('./submission/', exist_ok=True)\n",
        "predictions.to_csv('./submission/submission.csv')\n",
        "\n",
        "# zip the folder (zipfile can be directly uploaded to codalab):\n",
        "make_archive('./submission', 'zip', './submission')"
      ],
      "metadata": {
        "id": "myIcE8BvDk0R",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QKVsLqARDn2f",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}